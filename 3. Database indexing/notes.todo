Cómo crear una tabla con 1M rows?:

  CREATE TABLE temp (t int);
  INSERT INTO TEMP (t) SELECT RANDOM() * 100 FROM generate_series(0, 1000000);

Qué es un índice?:
  Es una estructura de datos que creamos sobre nuestras tablas y que intenta analizar y resumir
  la tabla para poder crear shortcuts. Se puede hacer una analogía con los labels que tienen
  algunos libros para indicarnos que estamos en cierto apartado.

  - EXPLAIN ANALYZE para ver cuánto se demora una consulta y qué hace internamente.
  - cuando buscamos por una expresión y no por un valor, e.g:

    SELECT name, salary FROM employees WHERE name LIKE '%esteban%'

    no se pueden aplicar los indexes que tenemos sobre las columnas, por lo que el motor de DB
    haría un full parallel sequential scan.

Explain explained:
  Este comando es una estimación, si queremos obtener información de data real tenemos que usar
  ANALYZE.

  - cost: consta de 2 números, el primero es lo que se tarda el motor en obtener la primera page,
    este número puede crecer en caso de que hagamos muchas operaciones antes de obtener la
    información (aggregation functions, por ejemplo). El segundo número es la estimación de cuánto
    cree el motor que va a tardar.
  - rows: una estimación de cuántas rows va a hacer fetch para esta consulta.
  - width: la suma de bytes para todas las columns.

Index Scan vs Index Only Scan:

  - Index Scan: cuando tenemos un index en una tabla pero por la consulta que estamos haciendo
    tenemos que volver a consultar a la tabla por más data que no tenía el index.
  - Index Only Scan: es cuando no tenemos que volver a la tabla a hacer fetch de más data, son
    las consultas ideales.
  - Podemos almacenar más data en un index (no va a ser usado para optimización o para búsquedas
    pero sí será fetched) de la siguiente manera

    CREATE INDEX id_idx ON stude  nts(id) INCLUDE (name);

    Esto se llama non-key indexes.

  - Tenemos que tener cuidado de no crear indexes demasiado pesados, estos podrían hacer las
    queries más pesadas.

key vs non-key indexes:

  - non-key indexes: son indexes que nos permiten incluir información en el index que no será usada
    para búsquedas pero sí estará incluida, por lo que podremos hacer un index only scan.
  - vacuum (verbose) table_name; esto nos dirá si tenemos algún error en la tabla o debemos remover
    algunas filas o columnas.
  - composite index: es un indeex que está compuesto de varias columnas y será más eficiente
    para queries que usen estas columnas. Cuando usamos un composite index, Postgres solamente
    puede acceder a la columna que está de lado izquierdo.

seq scan vs index scan vs bitmap index scan:
  - index scan: el motor decide usar esta estrategia cuando estamos consultando por un conjunto
    no tan grande de información pero igualmente tenemos que ir al heap a traer más data.
  - seq scan o table scan: es analizar toda la tabla por completo de manera secuencia, Postgres
    maneja varios workers para hacer estas queries más rápidas. El motor suele usarlas cuando
    tenemos que obtener mucha info.
  - bitmap index scan: el motor decide usar esta estrategia cuando no vamos a traer una cantidad
    tan grande de información pero sí nos será de utilidad usar el index en la consulta. Lo que
    hace es un bitmap de las pages y va mapeando cuáles son las que vamos a obtener y luego los
    obtiene todos de un sólo hit al heap. Luego a esto tiene que hacer un recheck porque en las
    pages pueden haber rows que no satisfagan lo que necesitamos. e.g: en caso de un filtro, en las
    pages podría haber rows que no cumplen nuestra condición.

concurrently creation of an index:
  cuando creamos un index puede tardar, especialmente en una tabla grande. Esto creará un lock en
  las transactions de escritura, lo cual puede perjudicarnos bastante.

  Postgres nos da una solución para esto

  CREATE INDEX CONCURRENTLY idx_name ON table(field);

  este index no hará un lock en las transactions; aunque, va a consumir más recursos.

bloom filters:
  es una estrategia que podemos utilizar para guardar ciertos bits de información en memoria y de
  acuerdo a estos tener una aproximación de si tenemos que realizar una consulta o con la data que
  tenemos en memoria ya es suficiente. Un caso de uso para esto sería un endpoint que valide la
  existencia de nombres de usuario.

working with a billion row table:

  - brute way: usar el multi-threading y multi-processing para partir la tabla en varios segmentos
    más pequeños y analizarlos de manera paralela.
  - limitar la cantidad del set:

    * partir la tabla en sets más pequeños usando indexes.
    * usar partitioning.
    * usar sharding.
  - no tener una tabla tan grande, buscar otras alternativas para evitar tener tantos registros.

b-trees:

  - Balanced Data structure for fast traversal.
  - root node: el nodo principal.
  - internal nodes: son los nodos que están en la parte intermedia del b-trees.
  - leaf nodes: son los últimos nodos, estos no tienen hijos.
  - cada nodo puede estar conformado por la cantidad de sus hijos - 1 como elements.
  - los elements se componen por una key y un value, siendo los keys los argumentos por los que
    se van a buscar y los values un valor que nos indica cuál es el row_id/tuple_id donde se
    encuentre el row. Esto es conocido como data pointer.
  - el index contiene info de en qué page se encuentra el row_id/tuple_id para evitar un full table
    scan.

b-trees limitations:

  - los internal nodes requieren más espacio en memoria a la hora de recorrer los nodos.
  - las queries que tienen cierto carácter aleatorio son más lenta por el random access. e.g:

    si quisiéramos obtener los registros que tienen a entre 1 y 5, tendríamos que recorrer el
    árbol 5 veces.

